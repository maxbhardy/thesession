{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096de4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import pathlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89053b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABCMusicConverter:\n",
    "    score: music21.stream.base.Score | None\n",
    "    destination: pathlib.Path\n",
    "    filename: str\n",
    "    midi_file: pathlib.Path | None\n",
    "    wav_file: pathlib.Path | None\n",
    "    mp3_file: pathlib.Path | None\n",
    "\n",
    "    instruments: dict = {\n",
    "        k.lower(): v\n",
    "        for k, v in vars(music21.instrument).items()\n",
    "        if hasattr(v, \"bestName\")\n",
    "    }\n",
    "\n",
    "    def __init__(self, abc: str, filename: str, destination: str | pathlib.Path = \".\"):\n",
    "        self.destination = pathlib.Path(destination)\n",
    "        self.filename = filename\n",
    "\n",
    "        self.midi_file = None\n",
    "        self.wav_file = None\n",
    "        self.mp3_file = None\n",
    "\n",
    "        self.score = music21.converter.parse(abc)\n",
    "\n",
    "    def to_midi(\n",
    "        self,\n",
    "        midi_file: str | pathlib.Path | None = None,\n",
    "        instrument: str | None = None,\n",
    "        tempo: int | None = None,\n",
    "    ) -> pathlib.Path:\n",
    "        # Path to new midi file\n",
    "        if midi_file is None:\n",
    "            self.midi_file = (self.destination / self.filename).with_suffix(\".mid\")\n",
    "        else:\n",
    "            self.midi_file = pathlib.Path(midi_file)\n",
    "\n",
    "        # Delete midi file if exists\n",
    "        if self.midi_file.exists():\n",
    "            self.midi_file.unlink()\n",
    "\n",
    "        if instrument is not None:\n",
    "            instrument = self.instruments.get(instrument.lower())\n",
    "            for p in self.score.parts:\n",
    "                p.insert(0, instrument())\n",
    "\n",
    "        if tempo is not None:\n",
    "            self.score.insert(0, music21.tempo.MetronomeMark(number=tempo))\n",
    "\n",
    "        # Convert to midi\n",
    "        mf = music21.midi.translate.music21ObjectToMidiFile(self.score)\n",
    "        mf.open(self.midi_file, \"wb\")\n",
    "        mf.write()\n",
    "        mf.close()\n",
    "\n",
    "        return self.midi_file\n",
    "\n",
    "    def to_wav(\n",
    "        self,\n",
    "        wav_file: str | pathlib.Path | None = None,\n",
    "        sound_font: str | pathlib.Path = \"GeneralUser-GS.sf2\",\n",
    "        sampling_rate: int = 16000,\n",
    "        **kwargs\n",
    "    ) -> pathlib.Path:\n",
    "        # Create midi file if necessary\n",
    "        if self.midi_file is None:\n",
    "            self.to_midi(**kwargs)\n",
    "\n",
    "        # Path to new wav file\n",
    "        if wav_file is None:\n",
    "            self.wav_file = (self.destination / self.filename).with_suffix(\".wav\")\n",
    "        else:\n",
    "            self.wav_file = pathlib.Path(wav_file)\n",
    "\n",
    "        # Remove file if exists\n",
    "        if self.wav_file.exists():\n",
    "            self.wav_file.unlink()\n",
    "\n",
    "        # Check if sound_font exists\n",
    "        sound_font = pathlib.Path(sound_font)\n",
    "        assert sound_font.exists()\n",
    "\n",
    "        # Convert to wav\n",
    "        command = [\n",
    "            \"fluidsynth\",\n",
    "            \"-ni\",\n",
    "            str(sound_font),\n",
    "            str(self.midi_file),\n",
    "            \"-F\",\n",
    "            str(self.wav_file),\n",
    "            \"-r\",\n",
    "            str(sampling_rate),\n",
    "        ]\n",
    "\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "\n",
    "        return self.wav_file\n",
    "\n",
    "    def to_mp3(\n",
    "        self, mp3_file: str | pathlib.Path | None = None, **kwargs\n",
    "    ) -> pathlib.Path:\n",
    "        # Create wave file if necessary\n",
    "        if self.wav_file is None:\n",
    "            self.to_wav(**kwargs)\n",
    "\n",
    "        # Path to new mp3 file\n",
    "        if mp3_file is None:\n",
    "            self.mp3_file = (self.destination / self.filename).with_suffix(\".mp3\")\n",
    "        else:\n",
    "            self.mp3_file = pathlib.Path(mp3_file)\n",
    "\n",
    "        # Remove file if exists\n",
    "        if self.mp3_file.exists():\n",
    "            self.mp3_file.unlink()\n",
    "\n",
    "        command = [\"ffmpeg\", \"-i\", str(self.wav_file), str(self.mp3_file)]\n",
    "\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "\n",
    "        return self.mp3_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c6ad8e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('cooleys_flute.wav')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABCMusicConverter(\"cooleys.abc\", \"cooleys\").to_mp3(instrument=\"violin\", tempo=180)\n",
    "ABCMusicConverter(\"cooleys.abc\", \"cooleys_flute\").to_wav(instrument=\"flute\", tempo=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe4d10",
   "metadata": {},
   "source": [
    "# CLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d679915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.venvs/session/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maxime/.venvs/session/lib64/python3.11/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load our best checkpoint in the paper.\n",
      "The checkpoint is already downloaded\n",
      "Load Checkpoint...\n",
      "logit_scale_a \t Loaded\n",
      "logit_scale_t \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_real.weight \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_imag.weight \t Loaded\n",
      "audio_branch.logmel_extractor.melW \t Loaded\n",
      "audio_branch.bn0.weight \t Loaded\n",
      "audio_branch.bn0.bias \t Loaded\n",
      "audio_branch.patch_embed.proj.weight \t Loaded\n",
      "audio_branch.patch_embed.proj.bias \t Loaded\n",
      "audio_branch.patch_embed.norm.weight \t Loaded\n",
      "audio_branch.patch_embed.norm.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.norm.weight \t Loaded\n",
      "audio_branch.norm.bias \t Loaded\n",
      "audio_branch.tscam_conv.weight \t Loaded\n",
      "audio_branch.tscam_conv.bias \t Loaded\n",
      "audio_branch.head.weight \t Loaded\n",
      "audio_branch.head.bias \t Loaded\n",
      "text_branch.embeddings.word_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.position_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.token_type_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.bias \t Loaded\n",
      "text_branch.pooler.dense.weight \t Loaded\n",
      "text_branch.pooler.dense.bias \t Loaded\n",
      "text_transform.sequential.0.weight \t Loaded\n",
      "text_transform.sequential.0.bias \t Loaded\n",
      "text_transform.sequential.3.weight \t Loaded\n",
      "text_transform.sequential.3.bias \t Loaded\n",
      "text_projection.0.weight \t Loaded\n",
      "text_projection.0.bias \t Loaded\n",
      "text_projection.2.weight \t Loaded\n",
      "text_projection.2.bias \t Loaded\n",
      "audio_transform.sequential.0.weight \t Loaded\n",
      "audio_transform.sequential.0.bias \t Loaded\n",
      "audio_transform.sequential.3.weight \t Loaded\n",
      "audio_transform.sequential.3.bias \t Loaded\n",
      "audio_projection.0.weight \t Loaded\n",
      "audio_projection.0.bias \t Loaded\n",
      "audio_projection.2.weight \t Loaded\n",
      "audio_projection.2.bias \t Loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from laion_clap import CLAP_Module\n",
    "\n",
    "# Load pretrained CLAP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLAP_Module(enable_fusion=False)  # disable fusion for audio-only use\n",
    "model.load_ckpt()  # downloads pretrained weights\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f64f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "waveform, sr = torchaudio.load(\"cooleys.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f844d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "\n",
    "def load_audio(filepath, target_sr=16000):\n",
    "    waveform, sr = torchaudio.load(filepath)\n",
    "    if sr != target_sr:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, target_sr)\n",
    "    return waveform.mean(dim=0).unsqueeze(0)  # Convert to mono, add batch dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724627b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor = load_audio(\"cooleys.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6944d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embedding = model.get_audio_embedding_from_data(audio_tensor, use_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9d5c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798a3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor2 = load_audio(\"cooleys_flute.wav\")\n",
    "with torch.no_grad():\n",
    "    embedding2 = model.get_audio_embedding_from_data(audio_tensor2, use_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08490ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7669e-02,  1.5185e-02,  5.8923e-02, -1.2021e-02,  9.5482e-02,\n",
       "         -3.4315e-03, -4.8566e-02,  1.8087e-02,  2.7128e-02,  1.4882e-02,\n",
       "         -6.4931e-02, -5.3605e-03,  4.7362e-02, -1.5416e-03, -5.5228e-03,\n",
       "         -4.7449e-02, -6.3107e-02, -2.0978e-02, -3.9053e-02,  7.6627e-02,\n",
       "          2.2313e-02,  1.4599e-01, -1.2977e-02,  4.0569e-03,  1.7864e-02,\n",
       "         -6.3704e-05,  1.7713e-02, -1.1361e-02,  1.8299e-02, -7.1580e-04,\n",
       "          5.2289e-02,  1.0640e-01,  9.7967e-03, -7.6950e-02,  1.0185e-01,\n",
       "         -6.2829e-02, -8.8202e-02, -1.9113e-02, -2.3685e-02,  6.1610e-02,\n",
       "         -6.7963e-02,  1.8895e-02, -8.2265e-02,  6.9059e-03,  2.3369e-02,\n",
       "         -5.4911e-02, -1.8842e-02,  9.8239e-03, -2.3676e-02,  3.2094e-03,\n",
       "          2.8726e-02, -6.8386e-02, -2.8290e-02,  3.8179e-02,  2.3533e-02,\n",
       "          2.7939e-02, -1.0502e-01, -2.0496e-02,  1.4185e-02,  2.3109e-02,\n",
       "          1.3942e-03, -1.5327e-02,  2.7790e-02, -3.3877e-02,  7.1842e-03,\n",
       "         -4.5241e-02,  1.3446e-02, -1.1526e-02,  1.2567e-02, -5.1197e-02,\n",
       "          7.6463e-02, -8.9984e-03,  5.8048e-03,  2.6143e-03, -2.5483e-02,\n",
       "          2.6038e-02, -2.6933e-02, -3.8239e-02,  1.3007e-02,  6.1947e-02,\n",
       "         -4.9913e-02,  3.2048e-03, -3.6125e-02, -3.6318e-02, -1.9313e-03,\n",
       "          1.4567e-02,  2.7961e-02,  1.9839e-02, -2.5609e-02, -9.3790e-04,\n",
       "          1.2901e-02, -1.2275e-02,  1.1157e-01, -1.5764e-02,  8.4079e-03,\n",
       "          2.9592e-02, -3.7360e-02,  1.2335e-02,  4.7600e-03,  3.6843e-02,\n",
       "          6.3843e-02,  3.2284e-02,  3.2298e-02,  4.3996e-02, -2.4711e-03,\n",
       "         -2.0065e-02, -4.0009e-02, -9.5931e-02,  3.1906e-02, -1.5132e-02,\n",
       "         -4.6309e-02,  1.4724e-02, -3.6216e-02, -2.2551e-02, -1.8336e-02,\n",
       "         -2.2430e-02, -2.1318e-02, -1.1799e-02,  7.0898e-02, -4.5046e-03,\n",
       "          1.5755e-02,  1.0732e-02,  3.8994e-02,  5.0490e-02, -8.3114e-03,\n",
       "         -3.7002e-02, -1.6120e-02, -5.8418e-02,  9.4940e-02,  2.1333e-02,\n",
       "         -9.9211e-03, -6.2728e-02,  1.3986e-02, -2.7838e-02, -2.1825e-03,\n",
       "          6.0066e-02, -7.4364e-02, -6.3895e-04,  7.6634e-02, -1.2999e-02,\n",
       "         -6.0070e-02,  2.1265e-02, -3.7496e-02, -5.4108e-02,  1.1871e-02,\n",
       "          2.4334e-02,  8.4563e-03,  5.0812e-02,  7.5948e-02, -1.8883e-02,\n",
       "         -5.7634e-02,  2.8607e-02,  6.0949e-02,  3.8568e-02,  5.2775e-02,\n",
       "          2.7527e-02,  7.5532e-02, -9.0569e-02,  5.0688e-02, -6.9685e-02,\n",
       "         -5.6384e-02, -3.2080e-02, -5.3854e-02, -1.8921e-02, -4.2635e-04,\n",
       "         -3.3067e-02,  1.7362e-02,  4.1400e-02, -6.0052e-03,  2.8421e-02,\n",
       "         -4.4227e-02,  2.6725e-02,  2.7857e-02, -4.7934e-02, -5.7500e-02,\n",
       "         -1.8230e-02,  8.7587e-02, -6.9907e-03,  3.6840e-04,  1.8056e-02,\n",
       "         -3.5449e-02,  2.2125e-02,  6.4963e-02,  9.1400e-03,  2.6864e-02,\n",
       "          3.5436e-02, -5.8584e-02,  9.1104e-03, -3.2351e-02, -4.4047e-02,\n",
       "         -2.6168e-02,  5.6318e-02, -1.1723e-02, -6.5374e-02, -4.8338e-04,\n",
       "         -3.6414e-02, -4.9606e-02, -9.2162e-03, -5.2929e-05,  7.7882e-03,\n",
       "          5.1841e-02, -3.0339e-03, -5.4696e-02,  7.5945e-02,  1.3743e-02,\n",
       "          1.0827e-02, -3.3166e-02,  1.0235e-02, -1.2753e-02, -5.1342e-02,\n",
       "         -4.6150e-02, -5.9453e-02, -8.3289e-02, -1.4061e-02,  8.4715e-03,\n",
       "         -2.4457e-03, -5.1431e-02, -4.5557e-02,  1.0696e-02, -5.7183e-02,\n",
       "         -5.1898e-02, -8.4182e-03,  9.6540e-03,  1.9268e-02,  7.2875e-02,\n",
       "         -6.2971e-03,  3.0059e-02,  8.0690e-03, -2.0346e-02, -8.1055e-03,\n",
       "          2.2984e-03,  5.8902e-02, -8.3047e-02, -2.8429e-03, -2.6826e-02,\n",
       "          8.5094e-02,  4.1604e-02,  1.3677e-02, -6.3525e-04,  7.3381e-03,\n",
       "          3.0179e-02,  1.5064e-02, -6.5921e-03,  9.0092e-03,  6.1877e-02,\n",
       "          1.5934e-02, -4.1786e-02,  2.0325e-02, -3.3680e-03,  1.2548e-02,\n",
       "          1.1362e-01,  7.2956e-03,  4.5618e-02, -5.7410e-02,  2.0604e-03,\n",
       "         -2.0034e-02, -9.6452e-03,  4.7225e-02, -3.3118e-02,  4.3839e-02,\n",
       "         -3.1505e-02, -5.1393e-02, -2.7517e-02, -2.9456e-02,  5.8725e-02,\n",
       "         -2.1384e-02, -4.4374e-02, -8.3860e-03,  4.3826e-02,  9.9049e-03,\n",
       "         -3.3895e-03, -4.3281e-02, -6.7754e-02, -3.2249e-02, -3.0200e-02,\n",
       "          3.1717e-02, -2.3019e-02,  5.3592e-03, -3.0771e-02, -3.9037e-02,\n",
       "         -4.7028e-02, -3.0506e-03,  2.7311e-02,  7.2930e-02, -8.7130e-02,\n",
       "         -9.7861e-02, -6.7512e-02, -5.8610e-03,  4.5279e-02, -6.0668e-02,\n",
       "          7.4106e-03,  6.8758e-03,  1.0754e-01, -3.6033e-02,  3.0272e-02,\n",
       "          1.9305e-02,  2.3199e-02, -8.5165e-02, -8.8674e-04,  3.4107e-02,\n",
       "          4.0013e-02, -2.9642e-02,  1.9370e-02, -3.9435e-02, -3.0359e-02,\n",
       "         -2.4278e-03, -1.0026e-01, -4.4654e-03, -9.5680e-03, -4.5223e-02,\n",
       "          1.6767e-03,  1.2058e-02, -3.4658e-03, -4.6501e-02,  6.8666e-02,\n",
       "         -5.8480e-02,  1.7141e-02, -3.9993e-02,  7.7505e-02,  1.2624e-02,\n",
       "          5.2764e-02,  7.9949e-03, -8.8418e-02, -4.6717e-02,  1.1252e-02,\n",
       "          3.2100e-03, -5.1533e-02,  1.2248e-02, -9.5305e-02,  3.1682e-02,\n",
       "          8.6549e-02,  7.1684e-02, -1.5821e-02, -1.0979e-01,  1.8385e-02,\n",
       "         -2.7420e-03, -8.2015e-02,  2.3513e-03,  3.6452e-02,  9.4391e-02,\n",
       "         -1.1557e-02,  4.0304e-02,  4.6135e-03, -8.6051e-03, -2.2118e-03,\n",
       "          2.1874e-02, -4.1950e-02, -3.4004e-02, -8.4831e-02,  3.6249e-02,\n",
       "          4.6780e-03, -3.0195e-02,  4.5087e-03, -2.9604e-02, -7.1159e-03,\n",
       "         -4.4169e-03,  9.6562e-03, -5.0729e-02, -6.8124e-03, -4.9036e-02,\n",
       "          3.4225e-02,  1.9160e-03,  2.3982e-03, -2.0151e-02, -1.0385e-02,\n",
       "          3.4693e-02, -3.2877e-02, -4.6218e-02, -8.3578e-02,  1.7581e-02,\n",
       "         -1.5481e-02,  4.1300e-02, -1.0439e-02, -3.7863e-02,  1.1126e-03,\n",
       "         -4.5021e-02,  2.1875e-02, -8.3483e-03,  1.0524e-01, -3.3227e-02,\n",
       "         -1.3542e-02, -1.5551e-02, -4.8727e-02, -6.6938e-02, -3.4434e-02,\n",
       "          4.6672e-02, -1.4535e-03, -8.8228e-03,  5.1746e-02, -1.5455e-03,\n",
       "          3.7599e-02,  1.0910e-01,  2.7552e-02, -5.8283e-02,  4.4477e-02,\n",
       "          4.9211e-02,  2.2387e-02,  3.1168e-02,  2.2965e-02, -4.0607e-02,\n",
       "         -3.0745e-02, -4.0373e-02,  4.7936e-02,  1.0307e-02, -3.8947e-02,\n",
       "         -8.4742e-04, -1.0546e-01, -3.7245e-02, -4.0562e-02,  3.8943e-02,\n",
       "          4.0697e-02, -8.0412e-03,  1.4180e-02, -5.4698e-03,  1.2905e-01,\n",
       "         -5.6150e-02,  2.7751e-02,  5.8521e-02,  3.6509e-02, -1.8071e-02,\n",
       "         -8.3333e-03, -2.2561e-03, -2.7988e-02,  7.1587e-02,  4.0813e-02,\n",
       "         -2.1932e-02,  1.0040e-01, -2.2563e-02, -6.1499e-02,  1.8456e-03,\n",
       "          3.3756e-02, -4.9047e-02, -2.8075e-03,  7.4152e-02, -2.3903e-02,\n",
       "         -2.8631e-02, -7.9486e-02, -1.9269e-02,  5.6423e-02, -3.6270e-02,\n",
       "          1.7435e-02, -2.3671e-02,  4.4154e-02, -8.6218e-02, -4.6167e-02,\n",
       "          1.3299e-02, -5.8445e-02, -4.1717e-02,  1.6352e-02,  2.4371e-02,\n",
       "          2.8669e-02, -2.3387e-02, -1.0352e-01,  2.9176e-02,  2.7567e-02,\n",
       "          2.0638e-02, -4.0431e-02, -9.1478e-02,  5.0655e-02,  5.5646e-02,\n",
       "          2.0435e-02, -1.6476e-02, -2.5497e-03, -3.9652e-02,  1.9171e-02,\n",
       "         -2.1915e-02, -4.7710e-03, -5.7404e-03, -1.7870e-02, -5.6356e-02,\n",
       "         -4.5545e-02, -1.4703e-02, -1.9992e-02, -4.7837e-02,  2.9422e-02,\n",
       "          9.3347e-02, -9.5375e-02, -7.1178e-02, -1.4952e-02, -2.4025e-02,\n",
       "          6.7695e-02, -1.3224e-02, -6.3696e-02,  3.8871e-02,  8.5918e-02,\n",
       "         -1.0195e-01, -3.1160e-02,  4.7134e-02,  3.8274e-03,  1.9367e-02,\n",
       "          7.0501e-02, -1.5833e-02,  5.3105e-03,  1.8742e-02, -5.0931e-02,\n",
       "          5.6058e-02, -3.6591e-02,  2.1672e-03,  7.4403e-02,  5.3290e-02,\n",
       "         -5.4239e-02,  8.9260e-03, -3.4594e-02,  1.7124e-02,  3.9757e-02,\n",
       "         -1.4432e-02, -2.0559e-02, -2.0907e-02,  7.1124e-02, -7.2491e-02,\n",
       "         -3.3827e-02, -3.1088e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8339f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7682], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(embedding, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "521c21fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('butterfly.wav')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABCMusicConverter(\"butterfly.abc\").to_wav(instrument=\"violin\", tempo=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b3d524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('butterfly_flute.wav')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABCMusicConverter(\"butterfly.abc\").to_wav(\n",
    "    \"butterfly_flute.wav\", instrument=\"flute\", tempo=160\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69fce7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor3 = load_audio(\"butterfly.wav\")\n",
    "with torch.no_grad():\n",
    "    embedding3 = model.get_audio_embedding_from_data(audio_tensor3, use_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679f2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor4 = load_audio(\"butterfly_flute.wav\")\n",
    "with torch.no_grad():\n",
    "    embedding4 = model.get_audio_embedding_from_data(audio_tensor4, use_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd7b0a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8442], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(embedding3, embedding4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0350f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.07):\n",
    "    \"\"\"\n",
    "    Contrastive loss using implicit negatives (NT-Xent).\n",
    "    Args:\n",
    "        z1: Tensor of shape (N, D) – embeddings from view 1 (e.g., anchors)\n",
    "        z2: Tensor of shape (N, D) – embeddings from view 2 (e.g., positives)\n",
    "    Returns:\n",
    "        Scalar contrastive loss\n",
    "    \"\"\"\n",
    "    batch_size = z1.size(0)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "\n",
    "    # Concatenate for full 2N x D\n",
    "    z = torch.cat([z1, z2], dim=0)  # shape: (2N, D)\n",
    "\n",
    "    # Cosine similarity matrix (2N x 2N)\n",
    "    sim = torch.matmul(z, z.T) / temperature  # shape: (2N, 2N)\n",
    "\n",
    "    # Mask self-similarity\n",
    "    mask = torch.eye(2 * batch_size, device=z.device).bool()\n",
    "    sim.masked_fill_(mask, -float(\"inf\"))  # ignore similarity to self\n",
    "\n",
    "    # Targets: for i in 0..N-1, positive pair is i<->i+N and i+N<->i\n",
    "    targets = torch.cat(\n",
    "        [torch.arange(batch_size, 2 * batch_size), torch.arange(0, batch_size)]\n",
    "    ).to(z.device)\n",
    "\n",
    "    loss = F.cross_entropy(sim, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5553e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = torch.cat([embedding, embedding3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6abdd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = torch.cat([embedding2, embedding4], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0764add5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1133, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_xent_loss(z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c8e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "with sqlite3.connect(\"database.db\") as con:\n",
    "    cur = con.execute(\"SELECT TuneVersion FROM TuneVersions WHERE TuneID = 9\")\n",
    "\n",
    "    res = cur.fetchall()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c97bcbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1\n",
      "T: Banish Misfortune\n",
      "R: jig\n",
      "M: 6/8\n",
      "L: 1/8\n",
      "K: Dmix\n",
      "|:fed cAG|A2d cAG|F2D DED|FEF GFG|\n",
      "AGA cAG|AGA cde|fed cAG|Ad^c d3:|\n",
      "|:f2d d^cd|f2g agf|e2c cBc|e2f gfe|\n",
      "f2g agf|e2f gfe|fed cAG|Ad^c d3:|\n",
      "|:f2g e2f|d2e c2d|ABA GAG|F2F GED|\n",
      "c3 cAG|AGA cde|fed cAG|Ad^c d3:|\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('banish_misfortune.wav')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(res[0][0])\n",
    "ABCMusicConverter(res[1][0], \"banish_misfortune\").to_wav(instrument=\"violin\", tempo=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e1ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
